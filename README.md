<<<<<<< HEAD
# ðŸ—ï¸ Optuna + MLflow Hyperparameter Optimization Pipeline

This project implements an **end-to-end machine-learning experimentation workflow** using:

âœ” **Optuna** â€” hyperparameter optimization  
âœ” **XGBoost Regressor** â€” model  
âœ” **MLflow** â€” experiment tracking  
âœ” **SQLite** â€” persistent study storage  
âœ” **Docker** â€” reproducible execution  

The model is trained on the **California Housing dataset** and evaluated using **Root Mean Squared Error (RMSE)**.

---

## ðŸ“‚ Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ objective.py
â”‚   â”œâ”€â”€ optimize.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ optuna_study.db
â”‚   â”œâ”€â”€ optimization_history.png
â”‚   â”œâ”€â”€ param_importance.png
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ mlruns/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ðŸ“¦ Installation (Local)

```bash
pip install -r requirements.txt
```

(Optional but recommended: use a virtual environment)

---

## â–¶ï¸ Running the Pipeline (Local)

### ðŸ”¹ Step 1 â€” Run Hyperparameter Optimization

```bash
python -m src.optimize
```

This will:

âœ… Load the dataset  
âœ… Run Optuna study  
âœ… Train XGBoost models  
âœ… Log runs to MLflow  
âœ… Save plots + database to `outputs/`

Generated files include:

```
outputs/optuna_study.db
outputs/optimization_history.png
outputs/param_importance.png
outputs/results.json
outputs/mlruns/
```

---

### ðŸ”¹ Step 2 â€” Evaluate the Best Model

```bash
python -m src.evaluate
```

This computes:

âœ” Best Trial Parameters  
âœ” Validation RMSE  
âœ” Test RMSE  

and stores them in:

```
outputs/results.json
```

---

### ðŸ”¹ Step 3 â€” View Experiments in MLflow UI

```bash
mlflow ui
```

Then open:

ðŸ‘‰ http://127.0.0.1:5000

You will see all experiment runs.

---

## ðŸ³ Running with Docker (Required for Task)

### Build image

```bash
docker build -t optuna-mlflow-pipeline .
```

### Run container

Windows PowerShell:

```bash
docker run -v ${PWD}/outputs:/app/outputs optuna-mlflow-pipeline
```

Mac / Linux:

```bash
docker run -v $(pwd)/outputs:/app/outputs optuna-mlflow-pipeline
```

Outputs appear on your host machine.

---

## ðŸ“Š Results Summary

### Baseline Model (Default XGBoost)

**RMSE â‰ˆ 0.46**

### Tuned Model (Optuna Best Trial)

**RMSE â‰ˆ 0.48**

> Note: Your exact values may differ slightly due to randomness.

---

## ðŸ“’ Notebook Analysis

Notebook:

```
notebooks/analysis.ipynb
```

Contains:

âœ” Data preprocessing  
âœ” Baseline vs Tuned performance  
âœ” Optuna visualizations  
âœ” Summary discussion  

---

## ðŸ“Œ Key Insights

- Optuna automates hyperparameter tuning efficiently  
- MLflow enables complete experiment tracking  
- Docker ensures consistent execution across systems  
- RMSE provides interpretable performance comparison  

---

## ðŸ› ï¸ Tech Stack

| Tool | Purpose |
|-----|--------|
| Python | Core language |
| XGBoost | Regression model |
| Optuna | Hyperparameter tuning |
| MLflow | Experiment tracking |
| SQLite | Study storage |
| Docker | Reproducibility |

---

## âœ… Requirements

All dependencies are listed in:

```
requirements.txt
```

Install using:

```bash
pip install -r requirements.txt
```

---

## âœï¸ Author

Sravani Karnataka

---

## âœ”ï¸ Status

Project **successfully implemented and tested** ðŸŽ‰
"# optuna-mlflow-pipeline" 
=======
# ðŸ—ï¸ Optuna + MLflow Hyperparameter Optimization Pipeline

This project implements an **end-to-end machine-learning experimentation workflow** using:

âœ” **Optuna** â€” hyperparameter optimization  
âœ” **XGBoost Regressor** â€” model  
âœ” **MLflow** â€” experiment tracking  
âœ” **SQLite** â€” persistent study storage  
âœ” **Docker** â€” reproducible execution  

The model is trained on the **California Housing dataset** and evaluated using **Root Mean Squared Error (RMSE)**.

---

## ðŸ“‚ Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ objective.py
â”‚   â”œâ”€â”€ optimize.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ optuna_study.db
â”‚   â”œâ”€â”€ optimization_history.png
â”‚   â”œâ”€â”€ param_importance.png
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ mlruns/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ðŸ“¦ Installation (Local)

```bash
pip install -r requirements.txt
```

(Optional but recommended: use a virtual environment)

---

## â–¶ï¸ Running the Pipeline (Local)

### ðŸ”¹ Step 1 â€” Run Hyperparameter Optimization

```bash
python -m src.optimize
```

This will:

âœ… Load the dataset  
âœ… Run Optuna study  
âœ… Train XGBoost models  
âœ… Log runs to MLflow  
âœ… Save plots + database to `outputs/`

Generated files include:

```
outputs/optuna_study.db
outputs/optimization_history.png
outputs/param_importance.png
outputs/results.json
outputs/mlruns/
```

---

### ðŸ”¹ Step 2 â€” Evaluate the Best Model

```bash
python -m src.evaluate
```

This computes:

âœ” Best Trial Parameters  
âœ” Validation RMSE  
âœ” Test RMSE  

and stores them in:

```
outputs/results.json
```

---

### ðŸ”¹ Step 3 â€” View Experiments in MLflow UI

```bash
mlflow ui
```

Then open:

ðŸ‘‰ http://127.0.0.1:5000

You will see all experiment runs.

---

## ðŸ³ Running with Docker (Required for Task)

### Build image

```bash
docker build -t optuna-mlflow-pipeline .
```

### Run container

Windows PowerShell:

```bash
docker run -v ${PWD}/outputs:/app/outputs optuna-mlflow-pipeline
```

Mac / Linux:

```bash
docker run -v $(pwd)/outputs:/app/outputs optuna-mlflow-pipeline
```

Outputs appear on your host machine.

---

## ðŸ“Š Results Summary

### Baseline Model (Default XGBoost)

**RMSE â‰ˆ 0.46**

### Tuned Model (Optuna Best Trial)

**RMSE â‰ˆ 0.48**

> Note: Your exact values may differ slightly due to randomness.

---

## ðŸ“’ Notebook Analysis

Notebook:

```
notebooks/analysis.ipynb
```

Contains:

âœ” Data preprocessing  
âœ” Baseline vs Tuned performance  
âœ” Optuna visualizations  
âœ” Summary discussion  

---

## ðŸ“Œ Key Insights

- Optuna automates hyperparameter tuning efficiently  
- MLflow enables complete experiment tracking  
- Docker ensures consistent execution across systems  
- RMSE provides interpretable performance comparison  

---

## ðŸ› ï¸ Tech Stack

| Tool | Purpose |
|-----|--------|
| Python | Core language |
| XGBoost | Regression model |
| Optuna | Hyperparameter tuning |
| MLflow | Experiment tracking |
| SQLite | Study storage |
| Docker | Reproducibility |

---

## âœ… Requirements

All dependencies are listed in:

```
requirements.txt
```

Install using:

```bash
pip install -r requirements.txt
```

---

## âœï¸ Author

Sravani Karnataka

---

## âœ”ï¸ Status

Project **successfully implemented and tested** ðŸŽ‰
"# optuna-mlflow-pipeline" 
>>>>>>> 3b90c6a49849faadace8b7b4a7abf7a3fe068746
